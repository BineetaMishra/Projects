{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREDIT CARD FRAUD DETECTION\n",
    "\n",
    "<strong> Problem Statement </strong>\n",
    "In this project we want to identify fraudulent transactions with Credit Cards. Our objective is to build a Fraud detection system using Machine learning techniques. In the past, such systems were rule-based. Machine learning offers powerful new ways.\n",
    "\n",
    "The project uses a dataset of 300,000 fully anonymized transactions. Each transation is labelled either fraudulent or not fraudulent. Note that prevalence of fraudulent transactions is very low in the dataset. Less than 0.1% of the card transactions are fraudulent. This means that a system predicting each transaction to be normal can reach an accuracy of over 99.9% despite not detecting any fraudulent transaction. This will necessitate adjustment techniques.\n",
    "\n",
    "It is a CSV file, contains 31 features, the last feature is used to classify the transaction whether it is a fraud or not.\n",
    "\n",
    "<b>Case Study:</b> Fraud detection is important to e-coomerce store and lot of money is used to prevention.\n",
    "We have a e-commerce store that sells books. Thousands of books were sold last year and toda we will use transaction data to build Fraud Detection System. We will use publica;ly available dataset.\n",
    "\n",
    "<b> Business Problem:</b> Build a classifier that give a new transaction can say whether fraudulent or not with confidence.<br>\n",
    "<b> Outcome: </b>\n",
    "0:Non-Fradulent <br>\n",
    "1:Fradulent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> dropping some columns after EDA that these columns give no useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop(columns=['Time','V13','V15','V22','V23','V24','V25','V26','V27','V28'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V12       V14       V16       V17  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.617801 -0.311169 -0.470401  0.207971   \n",
       "1  0.085102 -0.255425 -0.166974  ...  1.065235 -0.143772  0.463917 -0.114805   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.066084 -0.165946 -2.890083  1.109969   \n",
       "3  0.377436 -1.387024 -0.054952  ...  0.178228 -0.287924 -1.059647 -0.684093   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.538196 -1.119670 -0.451449 -0.237033   \n",
       "\n",
       "        V18       V19       V20       V21  Amount  Class  \n",
       "0  0.025791  0.403993  0.251412 -0.018307  149.62      0  \n",
       "1 -0.183361 -0.145783 -0.069083 -0.225775    2.69      0  \n",
       "2 -0.121359 -2.261857  0.524980  0.247998  378.66      0  \n",
       "3  1.965775 -1.232622 -0.208038 -0.108300  123.50      0  \n",
       "4 -0.038195  0.803487  0.408542 -0.009431   69.99      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalising the amount range using Standard Scaler\n",
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Scaled_Amount']= sc.fit_transform(df['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['Amount'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>Class</th>\n",
       "      <th>Scaled_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V12       V14       V16       V17  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.617801 -0.311169 -0.470401  0.207971   \n",
       "1  0.085102 -0.255425 -0.166974  ...  1.065235 -0.143772  0.463917 -0.114805   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.066084 -0.165946 -2.890083  1.109969   \n",
       "3  0.377436 -1.387024 -0.054952  ...  0.178228 -0.287924 -1.059647 -0.684093   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.538196 -1.119670 -0.451449 -0.237033   \n",
       "\n",
       "        V18       V19       V20       V21  Class  Scaled_Amount  \n",
       "0  0.025791  0.403993  0.251412 -0.018307      0       0.244964  \n",
       "1 -0.183361 -0.145783 -0.069083 -0.225775      0      -0.342475  \n",
       "2 -0.121359 -2.261857  0.524980  0.247998      0       1.160686  \n",
       "3  1.965775 -1.232622 -0.208038 -0.108300      0       0.140534  \n",
       "4 -0.038195  0.803487  0.408542 -0.009431      0      -0.073403  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df.loc[:,df.columns != 'Class']\n",
    "y=df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>Scaled_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V14       V16  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.311169 -0.470401   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235 -0.143772  0.463917   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084 -0.165946 -2.890083   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228 -0.287924 -1.059647   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196 -1.119670 -0.451449   \n",
       "\n",
       "        V17       V18       V19       V20       V21  Scaled_Amount  \n",
       "0  0.207971  0.025791  0.403993  0.251412 -0.018307       0.244964  \n",
       "1 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775      -0.342475  \n",
       "2  1.109969 -0.121359 -2.261857  0.524980  0.247998       1.160686  \n",
       "3 -0.684093  1.965775 -1.232622 -0.208038 -0.108300       0.140534  \n",
       "4 -0.237033 -0.038195  0.803487  0.408542 -0.009431      -0.073403  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying machine learning algorithms\n",
    "<b> Creating a function that will give the Following output when any model is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def print_score(clf, x_train, y_train, x_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(x_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(x_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 99.92%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                       0           1  accuracy      macro avg   weighted avg\n",
      "precision       0.999332    0.885185  0.999197       0.942259       0.999136\n",
      "recall          0.999864    0.611253  0.999197       0.805558       0.999197\n",
      "f1-score        0.999598    0.723147  0.999197       0.861372       0.999123\n",
      "support    227454.000000  391.000000  0.999197  227845.000000  227845.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[227423     31]\n",
      " [   152    239]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 99.92%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0           1  accuracy     macro avg  weighted avg\n",
      "precision      0.999314    0.885714  0.999175      0.942514      0.999113\n",
      "recall         0.999859    0.613861  0.999175      0.806860      0.999175\n",
      "f1-score       0.999587    0.725146  0.999175      0.862367      0.999100\n",
      "support    56861.000000  101.000000  0.999175  56962.000000  56962.000000\n",
      "_______________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_LR = LogisticRegression(random_state=0)\n",
    "\n",
    "clf_LR.fit(x_train,y_train)\n",
    "print_score(clf_LR, x_train, y_train, x_test, y_test, train=True)\n",
    "print_score(clf_LR, x_train, y_train, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE # Recurssive Feature Elimination\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebineet\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass n_features_to_select=4 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Reducing the features to 20 from 42\n",
    "clf = LogisticRegression(random_state=0)\n",
    "rfe = RFE(clf, 4)\n",
    "rfe= rfe.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True False False False False False  True False False\n",
      "  True  True False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "# summarise the selection attributes\n",
    "# which columns are selected(True) and which are not (False)\n",
    "print(rfe.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V4', 'V10', 'V14', 'V16'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15,  8, 11,  1,  5, 10, 17,  2, 13,  1,  4, 16,  1,  1,  7, 14, 12,\n",
       "        6,  3,  9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting Test Set\n",
    "clf.fit(x_train[x_train.columns[rfe.support_]],y_train)\n",
    "y_pred = clf.predict(x_test[x_test.columns[rfe.support_]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56853     8]\n",
      " [   42    59]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9991222218320986"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Making the confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm= confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V4</td>\n",
       "      <td>0.483711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V10</td>\n",
       "      <td>-0.286240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V14</td>\n",
       "      <td>-0.769235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V16</td>\n",
       "      <td>-0.293106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  features      coef\n",
       "0       V4  0.483711\n",
       "1      V10 -0.286240\n",
       "2      V14 -0.769235\n",
       "3      V16 -0.293106"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyzing Coefficients\n",
    "pd.concat([pd.DataFrame(x_train[x_train.columns[rfe.support_]].columns, columns = [\"features\"]),\n",
    "           pd.DataFrame(np.transpose(clf.coef_), columns = [\"coef\"])\n",
    "           ],axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Fold Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies= cross_val_score(estimator=clf_LR,\n",
    "                           X=x_train,\n",
    "                           y=y_train,\n",
    "                           cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99912221, 0.99918804, 0.99920999, 0.99929777, 0.99905638])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will show all 10 fold accuracies\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999174877658057"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "The accuracy is so high because the dataset is an imbalanced datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with data imbalance part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>Scaled_Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133981</th>\n",
       "      <td>1.470820</td>\n",
       "      <td>-1.093877</td>\n",
       "      <td>0.586213</td>\n",
       "      <td>-1.427984</td>\n",
       "      <td>-1.484319</td>\n",
       "      <td>-0.449748</td>\n",
       "      <td>-1.120350</td>\n",
       "      <td>-0.197704</td>\n",
       "      <td>-1.783109</td>\n",
       "      <td>1.369121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310096</td>\n",
       "      <td>-0.811774</td>\n",
       "      <td>-0.056602</td>\n",
       "      <td>0.096182</td>\n",
       "      <td>0.311133</td>\n",
       "      <td>-0.259984</td>\n",
       "      <td>-0.138396</td>\n",
       "      <td>-0.058275</td>\n",
       "      <td>-0.166119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202199</th>\n",
       "      <td>-0.303567</td>\n",
       "      <td>0.342453</td>\n",
       "      <td>1.393910</td>\n",
       "      <td>-0.427824</td>\n",
       "      <td>0.120050</td>\n",
       "      <td>0.162231</td>\n",
       "      <td>0.286003</td>\n",
       "      <td>0.078517</td>\n",
       "      <td>1.044161</td>\n",
       "      <td>-0.390909</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.012398</td>\n",
       "      <td>-0.171312</td>\n",
       "      <td>-0.171866</td>\n",
       "      <td>-0.415294</td>\n",
       "      <td>0.650071</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>0.092123</td>\n",
       "      <td>0.223831</td>\n",
       "      <td>-0.277746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30388</th>\n",
       "      <td>1.387402</td>\n",
       "      <td>-1.247700</td>\n",
       "      <td>0.658385</td>\n",
       "      <td>-1.476512</td>\n",
       "      <td>-1.620395</td>\n",
       "      <td>-0.258452</td>\n",
       "      <td>-1.263674</td>\n",
       "      <td>-0.014959</td>\n",
       "      <td>-1.919455</td>\n",
       "      <td>1.558467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041404</td>\n",
       "      <td>-0.417492</td>\n",
       "      <td>0.125204</td>\n",
       "      <td>-0.027769</td>\n",
       "      <td>0.855301</td>\n",
       "      <td>-0.045213</td>\n",
       "      <td>-0.165782</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>-0.113344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84447</th>\n",
       "      <td>-0.957317</td>\n",
       "      <td>-3.729433</td>\n",
       "      <td>-1.130661</td>\n",
       "      <td>1.100066</td>\n",
       "      <td>-1.717646</td>\n",
       "      <td>-0.533478</td>\n",
       "      <td>1.488717</td>\n",
       "      <td>-0.349142</td>\n",
       "      <td>0.091474</td>\n",
       "      <td>-0.498225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204622</td>\n",
       "      <td>0.960795</td>\n",
       "      <td>0.070022</td>\n",
       "      <td>0.007324</td>\n",
       "      <td>0.111324</td>\n",
       "      <td>0.159097</td>\n",
       "      <td>2.118664</td>\n",
       "      <td>0.647212</td>\n",
       "      <td>4.212585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162607</th>\n",
       "      <td>0.044414</td>\n",
       "      <td>0.916702</td>\n",
       "      <td>0.281566</td>\n",
       "      <td>-0.617775</td>\n",
       "      <td>0.546759</td>\n",
       "      <td>-0.986355</td>\n",
       "      <td>1.039814</td>\n",
       "      <td>-0.219661</td>\n",
       "      <td>-0.155303</td>\n",
       "      <td>-0.439570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539467</td>\n",
       "      <td>-0.037840</td>\n",
       "      <td>-0.167457</td>\n",
       "      <td>-0.421102</td>\n",
       "      <td>-0.908610</td>\n",
       "      <td>-0.133821</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>-0.251856</td>\n",
       "      <td>-0.349671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32463</th>\n",
       "      <td>1.218485</td>\n",
       "      <td>-0.988210</td>\n",
       "      <td>0.998254</td>\n",
       "      <td>-0.704519</td>\n",
       "      <td>-1.576072</td>\n",
       "      <td>-0.089468</td>\n",
       "      <td>-1.303595</td>\n",
       "      <td>0.317841</td>\n",
       "      <td>-0.367926</td>\n",
       "      <td>0.779892</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.883389</td>\n",
       "      <td>0.202889</td>\n",
       "      <td>1.423518</td>\n",
       "      <td>0.275562</td>\n",
       "      <td>-0.616294</td>\n",
       "      <td>0.082365</td>\n",
       "      <td>-0.010810</td>\n",
       "      <td>0.467524</td>\n",
       "      <td>-0.193346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116732</th>\n",
       "      <td>-0.266467</td>\n",
       "      <td>0.956125</td>\n",
       "      <td>1.198786</td>\n",
       "      <td>-0.510644</td>\n",
       "      <td>0.893077</td>\n",
       "      <td>0.262564</td>\n",
       "      <td>0.850658</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.584000</td>\n",
       "      <td>0.037962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693954</td>\n",
       "      <td>-0.173463</td>\n",
       "      <td>0.655972</td>\n",
       "      <td>-1.305537</td>\n",
       "      <td>0.422226</td>\n",
       "      <td>0.812004</td>\n",
       "      <td>0.296084</td>\n",
       "      <td>-0.304140</td>\n",
       "      <td>-0.338996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122560</th>\n",
       "      <td>1.163792</td>\n",
       "      <td>0.212417</td>\n",
       "      <td>0.540331</td>\n",
       "      <td>1.315578</td>\n",
       "      <td>-0.246162</td>\n",
       "      <td>-0.217715</td>\n",
       "      <td>-0.023605</td>\n",
       "      <td>0.023107</td>\n",
       "      <td>0.266675</td>\n",
       "      <td>-0.085484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320393</td>\n",
       "      <td>0.196921</td>\n",
       "      <td>-0.395852</td>\n",
       "      <td>0.085578</td>\n",
       "      <td>-0.884918</td>\n",
       "      <td>-0.482589</td>\n",
       "      <td>-0.200455</td>\n",
       "      <td>-0.185168</td>\n",
       "      <td>-0.325643</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224548</th>\n",
       "      <td>2.272594</td>\n",
       "      <td>-1.535335</td>\n",
       "      <td>-0.693490</td>\n",
       "      <td>-1.625756</td>\n",
       "      <td>-1.516127</td>\n",
       "      <td>-0.451512</td>\n",
       "      <td>-1.457541</td>\n",
       "      <td>0.028303</td>\n",
       "      <td>-1.053188</td>\n",
       "      <td>1.770232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.938033</td>\n",
       "      <td>-0.085696</td>\n",
       "      <td>-0.087821</td>\n",
       "      <td>0.158394</td>\n",
       "      <td>0.779032</td>\n",
       "      <td>0.201567</td>\n",
       "      <td>-0.526074</td>\n",
       "      <td>-0.134616</td>\n",
       "      <td>-0.325243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>-0.384234</td>\n",
       "      <td>1.015288</td>\n",
       "      <td>1.359077</td>\n",
       "      <td>0.240638</td>\n",
       "      <td>0.076040</td>\n",
       "      <td>-0.530719</td>\n",
       "      <td>0.366273</td>\n",
       "      <td>0.126172</td>\n",
       "      <td>1.261815</td>\n",
       "      <td>-0.852032</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.816768</td>\n",
       "      <td>1.526462</td>\n",
       "      <td>0.176455</td>\n",
       "      <td>1.160916</td>\n",
       "      <td>-0.010953</td>\n",
       "      <td>-0.635733</td>\n",
       "      <td>-0.121413</td>\n",
       "      <td>-0.415450</td>\n",
       "      <td>-0.345313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "133981  1.470820 -1.093877  0.586213 -1.427984 -1.484319 -0.449748 -1.120350   \n",
       "202199 -0.303567  0.342453  1.393910 -0.427824  0.120050  0.162231  0.286003   \n",
       "30388   1.387402 -1.247700  0.658385 -1.476512 -1.620395 -0.258452 -1.263674   \n",
       "84447  -0.957317 -3.729433 -1.130661  1.100066 -1.717646 -0.533478  1.488717   \n",
       "162607  0.044414  0.916702  0.281566 -0.617775  0.546759 -0.986355  1.039814   \n",
       "32463   1.218485 -0.988210  0.998254 -0.704519 -1.576072 -0.089468 -1.303595   \n",
       "116732 -0.266467  0.956125  1.198786 -0.510644  0.893077  0.262564  0.850658   \n",
       "122560  1.163792  0.212417  0.540331  1.315578 -0.246162 -0.217715 -0.023605   \n",
       "224548  2.272594 -1.535335 -0.693490 -1.625756 -1.516127 -0.451512 -1.457541   \n",
       "6568   -0.384234  1.015288  1.359077  0.240638  0.076040 -0.530719  0.366273   \n",
       "\n",
       "              V8        V9       V10  ...       V12       V14       V16  \\\n",
       "133981 -0.197704 -1.783109  1.369121  ... -0.310096 -0.811774 -0.056602   \n",
       "202199  0.078517  1.044161 -0.390909  ... -1.012398 -0.171312 -0.171866   \n",
       "30388  -0.014959 -1.919455  1.558467  ... -0.041404 -0.417492  0.125204   \n",
       "84447  -0.349142  0.091474 -0.498225  ...  0.204622  0.960795  0.070022   \n",
       "162607 -0.219661 -0.155303 -0.439570  ...  0.539467 -0.037840 -0.167457   \n",
       "32463   0.317841 -0.367926  0.779892  ... -0.883389  0.202889  1.423518   \n",
       "116732 -0.114955 -0.584000  0.037962  ...  0.693954 -0.173463  0.655972   \n",
       "122560  0.023107  0.266675 -0.085484  ...  0.320393  0.196921 -0.395852   \n",
       "224548  0.028303 -1.053188  1.770232  ... -0.938033 -0.085696 -0.087821   \n",
       "6568    0.126172  1.261815 -0.852032  ... -3.816768  1.526462  0.176455   \n",
       "\n",
       "             V17       V18       V19       V20       V21  Scaled_Amount  Class  \n",
       "133981  0.096182  0.311133 -0.259984 -0.138396 -0.058275      -0.166119      0  \n",
       "202199 -0.415294  0.650071  0.112403  0.092123  0.223831      -0.277746      0  \n",
       "30388  -0.027769  0.855301 -0.045213 -0.165782  0.004266      -0.113344      0  \n",
       "84447   0.007324  0.111324  0.159097  2.118664  0.647212       4.212585      0  \n",
       "162607 -0.421102 -0.908610 -0.133821  0.001114 -0.251856      -0.349671      0  \n",
       "32463   0.275562 -0.616294  0.082365 -0.010810  0.467524      -0.193346      0  \n",
       "116732 -1.305537  0.422226  0.812004  0.296084 -0.304140      -0.338996      0  \n",
       "122560  0.085578 -0.884918 -0.482589 -0.200455 -0.185168      -0.325643      0  \n",
       "224548  0.158394  0.779032  0.201567 -0.526074 -0.134616      -0.325243      0  \n",
       "6568    1.160916 -0.010953 -0.635733 -0.121413 -0.415450      -0.345313      0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the training df by remerging X_train and y_train\n",
    "df_train = x_train.join(y_train)\n",
    "df_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227454\n",
      "-----------\n",
      "391\n",
      "-----------\n",
      "0    227454\n",
      "1       391\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df_train[df_train.Class==0]\n",
    "df_minority = df_train[df_train.Class==1]\n",
    "\n",
    "print(df_majority.Class.count())\n",
    "print(\"-----------\")\n",
    "print(df_minority.Class.count())\n",
    "print(\"-----------\")\n",
    "print(df_train.Class.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UpSampling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    227454\n",
       "0    227454\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=227454,    # to match majority class\n",
    "                                 random_state=587) # reproducible results\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "# Display new class counts\n",
    "df_upsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_upsampled = df_upsampled.drop(['Class'], axis= 1)\n",
    "y_upsampled = df_upsampled.Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression on UpSampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 80.52%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                       0              1  accuracy      macro avg  \\\n",
      "precision       0.719716       0.999777   0.80524       0.859746   \n",
      "recall          0.999864       0.610616   0.80524       0.805240   \n",
      "f1-score        0.836969       0.758175   0.80524       0.797572   \n",
      "support    227454.000000  227454.000000   0.80524  454908.000000   \n",
      "\n",
      "            weighted avg  \n",
      "precision       0.859746  \n",
      "recall          0.805240  \n",
      "f1-score        0.797572  \n",
      "support    454908.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[227423     31]\n",
      " [ 88567 138887]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 99.92%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0           1  accuracy     macro avg  weighted avg\n",
      "precision      0.999314    0.885714  0.999175      0.942514      0.999113\n",
      "recall         0.999859    0.613861  0.999175      0.806860      0.999175\n",
      "f1-score       0.999587    0.725146  0.999175      0.862367      0.999100\n",
      "support    56861.000000  101.000000  0.999175  56962.000000  56962.000000\n",
      "_______________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_LR = LogisticRegression(random_state=0)\n",
    "\n",
    "clf_LR.fit(x_train,y_train)\n",
    "print_score(clf_LR, x_upsampled, y_upsampled, x_test, y_test, train=True)\n",
    "print_score(clf_LR, x_upsampled, y_upsampled, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down-Sampling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    391\n",
       "0    391\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=391,     # to match minority class\n",
    "                                 random_state=24) # reproducible results\n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "# Display new class counts\n",
    "df_downsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_downsampled = df_downsampled.drop(['Class'], axis = 1)\n",
    "y_downsampled = df_downsampled.Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression on Down-Sampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 80.56%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.720074    1.000000  0.805627    0.860037      0.860037\n",
      "recall       1.000000    0.611253  0.805627    0.805627      0.805627\n",
      "f1-score     0.837259    0.758730  0.805627    0.797995      0.797995\n",
      "support    391.000000  391.000000  0.805627  782.000000    782.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[391   0]\n",
      " [152 239]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 99.92%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0           1  accuracy     macro avg  weighted avg\n",
      "precision      0.999314    0.885714  0.999175      0.942514      0.999113\n",
      "recall         0.999859    0.613861  0.999175      0.806860      0.999175\n",
      "f1-score       0.999587    0.725146  0.999175      0.862367      0.999100\n",
      "support    56861.000000  101.000000  0.999175  56962.000000  56962.000000\n",
      "_______________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_LR = LogisticRegression(random_state=0)\n",
    "\n",
    "clf_LR.fit(x_train,y_train)\n",
    "print_score(clf_LR, x_downsampled, y_downsampled, x_test, y_test, train=True)\n",
    "print_score(clf_LR, x_downsampled, y_downsampled, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle file saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'C://Users//ebineet//Documents//Deployment//Deployment//Credit_Card_Claasification_model.sav'\n",
    "pickle.dump(clf_LR, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'C://Users//ebineet//Documents//Deployment//Deployment//Credit_Card_model.p'\n",
    "pickle.dump(clf_LR, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
