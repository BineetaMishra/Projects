{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREDIT CARD FRAUD DETECTION\n",
    "\n",
    "<strong> Problem Statement </strong>\n",
    "In this project we want to identify fraudulent transactions with Credit Cards. Our objective is to build a Fraud detection system using Machine learning techniques. In the past, such systems were rule-based. Machine learning offers powerful new ways.\n",
    "\n",
    "The project uses a dataset of 300,000 fully anonymized transactions. Each transation is labelled either fraudulent or not fraudulent. Note that prevalence of fraudulent transactions is very low in the dataset. Less than 0.1% of the card transactions are fraudulent. This means that a system predicting each transaction to be normal can reach an accuracy of over 99.9% despite not detecting any fraudulent transaction. This will necessitate adjustment techniques.\n",
    "\n",
    "It is a CSV file, contains 31 features, the last feature is used to classify the transaction whether it is a fraud or not.\n",
    "\n",
    "<b>Case Study:</b> Fraud detection is important to e-coomerce store and lot of money is used to prevention.\n",
    "We have a e-commerce store that sells books. Thousands of books were sold last year and toda we will use transaction data to build Fraud Detection System. We will use publica;ly available dataset.\n",
    "\n",
    "<b> Business Problem:</b> Build a classifier that give a new transaction can say whether fraudulent or not with confidence.<br>\n",
    "<b> Outcome: </b>\n",
    "0:Non-Fradulent <br>\n",
    "1:Fradulent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> dropping some columns after EDA that these columns give no useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop(columns=['Time','V13','V15','V22','V23','V24','V25','V26','V27','V28'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V12       V14       V16       V17  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.617801 -0.311169 -0.470401  0.207971   \n",
       "1  0.085102 -0.255425 -0.166974  ...  1.065235 -0.143772  0.463917 -0.114805   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.066084 -0.165946 -2.890083  1.109969   \n",
       "3  0.377436 -1.387024 -0.054952  ...  0.178228 -0.287924 -1.059647 -0.684093   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.538196 -1.119670 -0.451449 -0.237033   \n",
       "\n",
       "        V18       V19       V20       V21  Amount  Class  \n",
       "0  0.025791  0.403993  0.251412 -0.018307  149.62      0  \n",
       "1 -0.183361 -0.145783 -0.069083 -0.225775    2.69      0  \n",
       "2 -0.121359 -2.261857  0.524980  0.247998  378.66      0  \n",
       "3  1.965775 -1.232622 -0.208038 -0.108300  123.50      0  \n",
       "4 -0.038195  0.803487  0.408542 -0.009431   69.99      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalising the amount range using Standard Scaler\n",
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Scaled_Amount']= sc.fit_transform(df['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['Amount'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>Class</th>\n",
       "      <th>Scaled_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V12       V14       V16       V17  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.617801 -0.311169 -0.470401  0.207971   \n",
       "1  0.085102 -0.255425 -0.166974  ...  1.065235 -0.143772  0.463917 -0.114805   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.066084 -0.165946 -2.890083  1.109969   \n",
       "3  0.377436 -1.387024 -0.054952  ...  0.178228 -0.287924 -1.059647 -0.684093   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.538196 -1.119670 -0.451449 -0.237033   \n",
       "\n",
       "        V18       V19       V20       V21  Class  Scaled_Amount  \n",
       "0  0.025791  0.403993  0.251412 -0.018307      0       0.244964  \n",
       "1 -0.183361 -0.145783 -0.069083 -0.225775      0      -0.342475  \n",
       "2 -0.121359 -2.261857  0.524980  0.247998      0       1.160686  \n",
       "3  1.965775 -1.232622 -0.208038 -0.108300      0       0.140534  \n",
       "4 -0.038195  0.803487  0.408542 -0.009431      0      -0.073403  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df.loc[:,df.columns != 'Class']\n",
    "y=df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>Scaled_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V14       V16  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.311169 -0.470401   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235 -0.143772  0.463917   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084 -0.165946 -2.890083   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228 -0.287924 -1.059647   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196 -1.119670 -0.451449   \n",
       "\n",
       "        V17       V18       V19       V20       V21  Scaled_Amount  \n",
       "0  0.207971  0.025791  0.403993  0.251412 -0.018307       0.244964  \n",
       "1 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775      -0.342475  \n",
       "2  1.109969 -0.121359 -2.261857  0.524980  0.247998       1.160686  \n",
       "3 -0.684093  1.965775 -1.232622 -0.208038 -0.108300       0.140534  \n",
       "4 -0.237033 -0.038195  0.803487  0.408542 -0.009431      -0.073403  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying machine learning algorithms\n",
    "<b> Creating a function that will give the Following output when any model is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def print_score(clf, x_train, y_train, x_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(x_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(x_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                  0      1  accuracy  macro avg  weighted avg\n",
      "precision       1.0    1.0       1.0        1.0           1.0\n",
      "recall          1.0    1.0       1.0        1.0           1.0\n",
      "f1-score        1.0    1.0       1.0        1.0           1.0\n",
      "support    227454.0  391.0       1.0   227845.0      227845.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[227454      0]\n",
      " [     0    391]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 99.93%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0           1  accuracy     macro avg  weighted avg\n",
      "precision      0.999560    0.826087   0.99928      0.912824      0.999253\n",
      "recall         0.999719    0.752475   0.99928      0.876097      0.999280\n",
      "f1-score       0.999640    0.787565   0.99928      0.893602      0.999263\n",
      "support    56861.000000  101.000000   0.99928  56962.000000  56962.000000\n",
      "_______________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_tree= DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "clf_tree.fit(x_train,y_train)\n",
    "print_score(clf_tree, x_train, y_train, x_test, y_test, train=True)\n",
    "print_score(clf_tree, x_train, y_train, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                  0      1  accuracy  macro avg  weighted avg\n",
      "precision       1.0    1.0       1.0        1.0           1.0\n",
      "recall          1.0    1.0       1.0        1.0           1.0\n",
      "f1-score        1.0    1.0       1.0        1.0           1.0\n",
      "support    227454.0  391.0       1.0   227845.0      227845.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[227454      0]\n",
      " [     0    391]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 99.95%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0           1  accuracy     macro avg  weighted avg\n",
      "precision      0.999631    0.930233  0.999526      0.964932      0.999508\n",
      "recall         0.999894    0.792079  0.999526      0.895987      0.999526\n",
      "f1-score       0.999763    0.855615  0.999526      0.927689      0.999507\n",
      "support    56861.000000  101.000000  0.999526  56962.000000  56962.000000\n",
      "_______________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf= RandomForestClassifier(random_state=0)\n",
    "\n",
    "clf_rf.fit(x_train,y_train)\n",
    "print_score(clf_rf, x_train, y_train, x_test, y_test, train=True)\n",
    "print_score(clf_rf, x_train, y_train, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebineet\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass n_features_to_select=4 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Reducing the features to 20 from 42\n",
    "clf = LogisticRegression(random_state=0)\n",
    "rfe = RFE(clf, 4)\n",
    "rfe= rfe.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True False False False False False  True False False\n",
      "  True  True False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "# summarise the selection attributes\n",
    "# which columns are selected(True) and which are not (False)\n",
    "print(rfe.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V4', 'V10', 'V14', 'V16'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15,  8, 11,  1,  5, 10, 17,  2, 13,  1,  4, 16,  1,  1,  7, 14, 12,\n",
       "        6,  3,  9])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting Test Set\n",
    "clf.fit(x_train[x_train.columns[rfe.support_]],y_train)\n",
    "y_pred = clf.predict(x_test[x_test.columns[rfe.support_]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56853     8]\n",
      " [   42    59]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9991222218320986"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Making the confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm= confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V4</td>\n",
       "      <td>0.483711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V10</td>\n",
       "      <td>-0.286240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V14</td>\n",
       "      <td>-0.769235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V16</td>\n",
       "      <td>-0.293106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  features      coef\n",
       "0       V4  0.483711\n",
       "1      V10 -0.286240\n",
       "2      V14 -0.769235\n",
       "3      V16 -0.293106"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyzing Coefficients\n",
    "pd.concat([pd.DataFrame(x_train[x_train.columns[rfe.support_]].columns, columns = [\"features\"]),\n",
    "           pd.DataFrame(np.transpose(clf.coef_), columns = [\"coef\"])\n",
    "           ],axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Fold Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies= cross_val_score(estimator=clf_LR,\n",
    "                           X=x_train,\n",
    "                           y=y_train,\n",
    "                           cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99912221, 0.99918804, 0.99920999, 0.99929777, 0.99905638])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will show all 10 fold accuracies\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999174877658057"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies= cross_val_score(estimator=clf_tree,\n",
    "                           X=x_train,\n",
    "                           y=y_train,\n",
    "                           cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991178213259013"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies= cross_val_score(estimator=clf_rf,\n",
    "                           X=x_train,\n",
    "                           y=y_train,\n",
    "                           cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995479382913823"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "accuracies_rbf= cross_val_score(estimator=model_RBF,\n",
    "                           X=x_train,\n",
    "                           y=y_train,\n",
    "                           cv=5)\n",
    "\n",
    "accuracies_Poly= cross_val_score(estimator=model_Poly,\n",
    "                           X=x_train,\n",
    "                           y=y_train,\n",
    "                           cv=5)\n",
    "\n",
    "\n",
    "accuracies_linear= cross_val_score(estimator=model_linear,\n",
    "                           X=x_train,\n",
    "                           y=y_train,\n",
    "                           cv=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "accuracies_rbf.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "accuracies_Poly.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "accuracies_linear.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "The accuracy is so high because the dataset is an imbalanced datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with data imbalance part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>Scaled_Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91399</th>\n",
       "      <td>-2.307939</td>\n",
       "      <td>-1.995021</td>\n",
       "      <td>1.633618</td>\n",
       "      <td>-2.413268</td>\n",
       "      <td>-0.867315</td>\n",
       "      <td>0.327203</td>\n",
       "      <td>2.607588</td>\n",
       "      <td>-1.267149</td>\n",
       "      <td>2.279375</td>\n",
       "      <td>-1.014836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.614645</td>\n",
       "      <td>-1.432970</td>\n",
       "      <td>0.052624</td>\n",
       "      <td>-1.265911</td>\n",
       "      <td>0.473202</td>\n",
       "      <td>0.333513</td>\n",
       "      <td>-0.600572</td>\n",
       "      <td>-0.393535</td>\n",
       "      <td>1.352354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276792</th>\n",
       "      <td>1.946051</td>\n",
       "      <td>0.675179</td>\n",
       "      <td>-0.797716</td>\n",
       "      <td>3.703470</td>\n",
       "      <td>0.524524</td>\n",
       "      <td>-0.383933</td>\n",
       "      <td>0.353888</td>\n",
       "      <td>-0.229634</td>\n",
       "      <td>-1.191897</td>\n",
       "      <td>1.528632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155767</td>\n",
       "      <td>0.333935</td>\n",
       "      <td>0.847830</td>\n",
       "      <td>-0.913748</td>\n",
       "      <td>-0.341869</td>\n",
       "      <td>-1.790636</td>\n",
       "      <td>-0.268672</td>\n",
       "      <td>0.234448</td>\n",
       "      <td>-0.334918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58008</th>\n",
       "      <td>-0.782950</td>\n",
       "      <td>1.351430</td>\n",
       "      <td>1.256045</td>\n",
       "      <td>0.368087</td>\n",
       "      <td>0.050375</td>\n",
       "      <td>-0.882264</td>\n",
       "      <td>0.660864</td>\n",
       "      <td>-0.222950</td>\n",
       "      <td>-0.387727</td>\n",
       "      <td>-0.028516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135776</td>\n",
       "      <td>-0.561515</td>\n",
       "      <td>0.038275</td>\n",
       "      <td>0.202122</td>\n",
       "      <td>-0.124503</td>\n",
       "      <td>0.602782</td>\n",
       "      <td>0.174696</td>\n",
       "      <td>-0.172119</td>\n",
       "      <td>-0.325523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176062</th>\n",
       "      <td>-3.034353</td>\n",
       "      <td>-0.262247</td>\n",
       "      <td>-0.385991</td>\n",
       "      <td>-3.142276</td>\n",
       "      <td>-1.622657</td>\n",
       "      <td>1.461466</td>\n",
       "      <td>-0.988286</td>\n",
       "      <td>1.724881</td>\n",
       "      <td>-2.101497</td>\n",
       "      <td>0.592260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601657</td>\n",
       "      <td>0.507125</td>\n",
       "      <td>-0.265931</td>\n",
       "      <td>1.082911</td>\n",
       "      <td>-0.342935</td>\n",
       "      <td>-1.396542</td>\n",
       "      <td>-0.628600</td>\n",
       "      <td>-0.129188</td>\n",
       "      <td>0.278468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266971</th>\n",
       "      <td>-2.347480</td>\n",
       "      <td>1.906698</td>\n",
       "      <td>0.518341</td>\n",
       "      <td>-0.379590</td>\n",
       "      <td>-0.888491</td>\n",
       "      <td>-0.563200</td>\n",
       "      <td>-0.383494</td>\n",
       "      <td>0.732846</td>\n",
       "      <td>0.319286</td>\n",
       "      <td>-0.411794</td>\n",
       "      <td>...</td>\n",
       "      <td>1.060598</td>\n",
       "      <td>0.072014</td>\n",
       "      <td>0.061557</td>\n",
       "      <td>-0.153071</td>\n",
       "      <td>-0.107327</td>\n",
       "      <td>0.371200</td>\n",
       "      <td>-0.344062</td>\n",
       "      <td>0.023564</td>\n",
       "      <td>-0.333239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132477</th>\n",
       "      <td>-1.024907</td>\n",
       "      <td>1.068628</td>\n",
       "      <td>2.159984</td>\n",
       "      <td>1.219775</td>\n",
       "      <td>-0.635047</td>\n",
       "      <td>0.747280</td>\n",
       "      <td>-0.478264</td>\n",
       "      <td>0.877752</td>\n",
       "      <td>0.058144</td>\n",
       "      <td>-0.486630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.239382</td>\n",
       "      <td>0.045725</td>\n",
       "      <td>-0.415310</td>\n",
       "      <td>0.514226</td>\n",
       "      <td>0.020502</td>\n",
       "      <td>0.674764</td>\n",
       "      <td>0.044567</td>\n",
       "      <td>-0.016759</td>\n",
       "      <td>-0.333279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268966</th>\n",
       "      <td>1.780541</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>-2.549174</td>\n",
       "      <td>1.574685</td>\n",
       "      <td>0.811630</td>\n",
       "      <td>-0.880434</td>\n",
       "      <td>0.755707</td>\n",
       "      <td>-0.285778</td>\n",
       "      <td>0.317556</td>\n",
       "      <td>-0.384304</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.723899</td>\n",
       "      <td>-0.708836</td>\n",
       "      <td>-0.114104</td>\n",
       "      <td>1.039761</td>\n",
       "      <td>0.260487</td>\n",
       "      <td>-0.420624</td>\n",
       "      <td>-0.036483</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>0.208822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242041</th>\n",
       "      <td>1.750367</td>\n",
       "      <td>-0.676421</td>\n",
       "      <td>-0.948436</td>\n",
       "      <td>0.966969</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>0.827662</td>\n",
       "      <td>-0.528501</td>\n",
       "      <td>0.250703</td>\n",
       "      <td>0.797027</td>\n",
       "      <td>0.348069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176625</td>\n",
       "      <td>0.286006</td>\n",
       "      <td>1.047363</td>\n",
       "      <td>-1.412892</td>\n",
       "      <td>1.338847</td>\n",
       "      <td>-0.091558</td>\n",
       "      <td>0.046298</td>\n",
       "      <td>0.270361</td>\n",
       "      <td>0.190510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254857</th>\n",
       "      <td>-0.779664</td>\n",
       "      <td>0.164888</td>\n",
       "      <td>0.777698</td>\n",
       "      <td>-0.266798</td>\n",
       "      <td>0.125544</td>\n",
       "      <td>0.077234</td>\n",
       "      <td>-0.542197</td>\n",
       "      <td>0.742019</td>\n",
       "      <td>0.241060</td>\n",
       "      <td>-0.788901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861052</td>\n",
       "      <td>0.336512</td>\n",
       "      <td>0.137659</td>\n",
       "      <td>-0.449354</td>\n",
       "      <td>0.935278</td>\n",
       "      <td>0.329377</td>\n",
       "      <td>-0.063056</td>\n",
       "      <td>0.462853</td>\n",
       "      <td>-0.333279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229018</th>\n",
       "      <td>2.279318</td>\n",
       "      <td>-0.733895</td>\n",
       "      <td>-3.498674</td>\n",
       "      <td>-2.038261</td>\n",
       "      <td>2.447428</td>\n",
       "      <td>2.684337</td>\n",
       "      <td>-0.380628</td>\n",
       "      <td>0.480325</td>\n",
       "      <td>-1.131160</td>\n",
       "      <td>0.953808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.629595</td>\n",
       "      <td>0.569641</td>\n",
       "      <td>0.355726</td>\n",
       "      <td>0.271427</td>\n",
       "      <td>-1.836285</td>\n",
       "      <td>0.531009</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.339869</td>\n",
       "      <td>-0.338237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "91399  -2.307939 -1.995021  1.633618 -2.413268 -0.867315  0.327203  2.607588   \n",
       "276792  1.946051  0.675179 -0.797716  3.703470  0.524524 -0.383933  0.353888   \n",
       "58008  -0.782950  1.351430  1.256045  0.368087  0.050375 -0.882264  0.660864   \n",
       "176062 -3.034353 -0.262247 -0.385991 -3.142276 -1.622657  1.461466 -0.988286   \n",
       "266971 -2.347480  1.906698  0.518341 -0.379590 -0.888491 -0.563200 -0.383494   \n",
       "132477 -1.024907  1.068628  2.159984  1.219775 -0.635047  0.747280 -0.478264   \n",
       "268966  1.780541  0.008474 -2.549174  1.574685  0.811630 -0.880434  0.755707   \n",
       "242041  1.750367 -0.676421 -0.948436  0.966969  0.050144  0.827662 -0.528501   \n",
       "254857 -0.779664  0.164888  0.777698 -0.266798  0.125544  0.077234 -0.542197   \n",
       "229018  2.279318 -0.733895 -3.498674 -2.038261  2.447428  2.684337 -0.380628   \n",
       "\n",
       "              V8        V9       V10  ...       V12       V14       V16  \\\n",
       "91399  -1.267149  2.279375 -1.014836  ... -0.614645 -1.432970  0.052624   \n",
       "276792 -0.229634 -1.191897  1.528632  ... -0.155767  0.333935  0.847830   \n",
       "58008  -0.222950 -0.387727 -0.028516  ...  0.135776 -0.561515  0.038275   \n",
       "176062  1.724881 -2.101497  0.592260  ... -0.601657  0.507125 -0.265931   \n",
       "266971  0.732846  0.319286 -0.411794  ...  1.060598  0.072014  0.061557   \n",
       "132477  0.877752  0.058144 -0.486630  ... -0.239382  0.045725 -0.415310   \n",
       "268966 -0.285778  0.317556 -0.384304  ... -0.723899 -0.708836 -0.114104   \n",
       "242041  0.250703  0.797027  0.348069  ...  0.176625  0.286006  1.047363   \n",
       "254857  0.742019  0.241060 -0.788901  ...  0.861052  0.336512  0.137659   \n",
       "229018  0.480325 -1.131160  0.953808  ... -0.629595  0.569641  0.355726   \n",
       "\n",
       "             V17       V18       V19       V20       V21  Scaled_Amount  Class  \n",
       "91399  -1.265911  0.473202  0.333513 -0.600572 -0.393535       1.352354      0  \n",
       "276792 -0.913748 -0.341869 -1.790636 -0.268672  0.234448      -0.334918      0  \n",
       "58008   0.202122 -0.124503  0.602782  0.174696 -0.172119      -0.325523      0  \n",
       "176062  1.082911 -0.342935 -1.396542 -0.628600 -0.129188       0.278468      0  \n",
       "266971 -0.153071 -0.107327  0.371200 -0.344062  0.023564      -0.333239      0  \n",
       "132477  0.514226  0.020502  0.674764  0.044567 -0.016759      -0.333279      0  \n",
       "268966  1.039761  0.260487 -0.420624 -0.036483  0.018670       0.208822      0  \n",
       "242041 -1.412892  1.338847 -0.091558  0.046298  0.270361       0.190510      0  \n",
       "254857 -0.449354  0.935278  0.329377 -0.063056  0.462853      -0.333279      0  \n",
       "229018  0.271427 -1.836285  0.531009  0.003502  0.339869      -0.338237      0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the training df by remerging X_train and y_train\n",
    "df_train = x_train.join(y_train)\n",
    "df_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227454\n",
      "-----------\n",
      "391\n",
      "-----------\n",
      "0    227454\n",
      "1       391\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df_train[df_train.Class==0]\n",
    "df_minority = df_train[df_train.Class==1]\n",
    "\n",
    "print(df_majority.Class.count())\n",
    "print(\"-----------\")\n",
    "print(df_minority.Class.count())\n",
    "print(\"-----------\")\n",
    "print(df_train.Class.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UpSampling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    227454\n",
       "0    227454\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=227454,    # to match majority class\n",
    "                                 random_state=587) # reproducible results\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "# Display new class counts\n",
    "df_upsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_upsampled = df_upsampled.drop(['Class'], axis= 1)\n",
    "y_upsampled = df_upsampled.Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression on UpSampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 80.52%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                       0              1  accuracy      macro avg  \\\n",
      "precision       0.719716       0.999777   0.80524       0.859746   \n",
      "recall          0.999864       0.610616   0.80524       0.805240   \n",
      "f1-score        0.836969       0.758175   0.80524       0.797572   \n",
      "support    227454.000000  227454.000000   0.80524  454908.000000   \n",
      "\n",
      "            weighted avg  \n",
      "precision       0.859746  \n",
      "recall          0.805240  \n",
      "f1-score        0.797572  \n",
      "support    454908.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[227423     31]\n",
      " [ 88567 138887]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 99.92%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0           1  accuracy     macro avg  weighted avg\n",
      "precision      0.999314    0.885714  0.999175      0.942514      0.999113\n",
      "recall         0.999859    0.613861  0.999175      0.806860      0.999175\n",
      "f1-score       0.999587    0.725146  0.999175      0.862367      0.999100\n",
      "support    56861.000000  101.000000  0.999175  56962.000000  56962.000000\n",
      "_______________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_LR = LogisticRegression(random_state=0)\n",
    "\n",
    "clf_LR.fit(x_train,y_train)\n",
    "print_score(clf_LR, x_upsampled, y_upsampled, x_test, y_test, train=True)\n",
    "print_score(clf_LR, x_upsampled, y_upsampled, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down-Sampling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    391\n",
       "0    391\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=391,     # to match minority class\n",
    "                                 random_state=24) # reproducible results\n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "# Display new class counts\n",
    "df_downsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_downsampled = df_downsampled.drop(['Class'], axis = 1)\n",
    "y_downsampled = df_downsampled.Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression on Down-Sampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 80.56%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.720074    1.000000  0.805627    0.860037      0.860037\n",
      "recall       1.000000    0.611253  0.805627    0.805627      0.805627\n",
      "f1-score     0.837259    0.758730  0.805627    0.797995      0.797995\n",
      "support    391.000000  391.000000  0.805627  782.000000    782.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[391   0]\n",
      " [152 239]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 99.92%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0           1  accuracy     macro avg  weighted avg\n",
      "precision      0.999314    0.885714  0.999175      0.942514      0.999113\n",
      "recall         0.999859    0.613861  0.999175      0.806860      0.999175\n",
      "f1-score       0.999587    0.725146  0.999175      0.862367      0.999100\n",
      "support    56861.000000  101.000000  0.999175  56962.000000  56962.000000\n",
      "_______________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_LR = LogisticRegression(random_state=0)\n",
    "\n",
    "clf_LR.fit(x_train,y_train)\n",
    "print_score(clf_LR, x_downsampled, y_downsampled, x_test, y_test, train=True)\n",
    "print_score(clf_LR, x_downsampled, y_downsampled, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=587)\n",
    "x_SMOTE, y_SMOTE = sm.fit(x_train, y_train)\n",
    "print(len(y_SMOTE))\n",
    "print(y_SMOTE.sum())\n",
    "print(y_SMOTE.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
