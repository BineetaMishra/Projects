{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement and Business Case\n",
    "\n",
    "The HR team collected extensive data on their employees and approached to develop a model that could predict which employees are more likely to quit. \n",
    "The team provided you with an extensive data, here's a sample of the dataset: \n",
    "<strong>\n",
    "1. Age\n",
    "2. BusinessTravel\n",
    "3. DailyRate\n",
    "4. Department\n",
    "5. DistanceFromHome\n",
    "6. Education\n",
    "7. EducationField\n",
    "8. EmployeeCount\n",
    "9. EmployeeNumber\n",
    "10. EnvironmentSatisfaction\n",
    "11. Gender\n",
    "12.  HourlyRate\n",
    "13. JobInvolvement\n",
    "14. JobLevel\n",
    "15. JobRole\n",
    "16. JobSatisfaction\n",
    "17. MaritalStatus\n",
    "18. MonthlyRate\n",
    "19. NumCompaniesWorked \n",
    "20. Over18\n",
    "21. OverTime\n",
    "22.  PercentSalaryHike\n",
    "23. PerformanceRating\n",
    "24. Attrition\n",
    "25. RelationshipSatisfaction \n",
    "26. StandardHours\n",
    "27. StockOptionLevel\n",
    "28. TotalWorkingYears\n",
    "29. TrainingTimesLastYear   \n",
    "30. WorkLifeBalance\n",
    "31. YearsAtCompany \n",
    "32.  YearsInCurrentRole\n",
    "33. YearsSinceLastPromotion \n",
    "34. YearsWithCurrManager\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>\n",
    "\n",
    "From EDA we concluded to use the following columns only:\n",
    "    1. Daily Rate\n",
    "    2. Distance From Home\n",
    "    3. Environment Satisfaction\n",
    "    4. Job Level\n",
    "    5. Job Satisfaction\n",
    "    6. Monthly Rate\n",
    "    7. Num Companies Worked\n",
    "    8. Years at Comapny\n",
    "    9. Years with manager\n",
    "    10. BusinessTravel\n",
    "    11. Department\n",
    "    12. EducationField\n",
    "    13 Gender\n",
    "    14. JobRole\n",
    "    15. MaritalStatus\n",
    "    16. Over Time\n",
    "    17. Age\n",
    "    \n",
    "Working on the Sacling and the Categorical VAriables part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,recall_score\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('Human_Resources.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['EmployeeCount', 'EmployeeNumber', 'Over18', 'StandardHours'], axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making seperate list for categorical variables\n",
    "categorical_col = []\n",
    "for column in new_df.columns:\n",
    "    if new_df[column].dtype == object:\n",
    "        categorical_col.append(column)\n",
    "        print(f\"{column} : {df[column].unique()}\")\n",
    "        print(\"====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Attrition'] = df.Attrition.astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Attrition.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling the Categorical Variables using Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col.remove('Attrition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform categorical data into dummies\n",
    "# categorical_col.remove(\"Attrition\")\n",
    "# data = pd.get_dummies(df, columns=categorical_col)\n",
    "# data.info()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label = LabelEncoder()\n",
    "for column in categorical_col:\n",
    "    df[column] = label.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.drop('Attrition', axis=1)\n",
    "y = df.Attrition\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_scaled= pd.DataFrame(sc.fit_transform(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_scaled= pd.DataFrame(sc.fit_transform(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put df_scaled have the columns of original new_df set\n",
    "xtrain_scaled.columns = new_df.columns.values\n",
    "xtest_scaled.columns = new_df.columns.values\n",
    "\n",
    "# take the indexes also\n",
    "xtrain_scaled.index = new_df.index.values\n",
    "xtest_scaled.index = new_df.index.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def print_score(clf, xtrain_scaled, y_train, xtest_scaled, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_LR = LogisticRegression(random_state=0)\n",
    "\n",
    "clf_LR.fit(x_train,y_train)\n",
    "print_score(clf_LR, xtrain_scaled, y_train, xtest_scaled, y_test, train=True)\n",
    "print_score(clf_LR, xtrain_scaled, y_train, xtest_scaled, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_tree= DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "clf_tree.fit(x_train,y_train)\n",
    "print_score(clf_tree, xtrain_scaled, y_train, xtest_scaled, y_test, train=True)\n",
    "print_score(clf_tree, xtrain_scaled, y_train, xtest_scaled, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf= RandomForestClassifier(random_state=0)\n",
    "\n",
    "clf_rf.fit(x_train,y_train)\n",
    "print_score(clf_rf, xtrain_scaled, y_train, xtest_scaled, y_test, train=True)\n",
    "print_score(clf_rf, xtrain_scaled, y_train, xtest_scaled, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter tuning on Tree Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arameters= {'max_depth':[3, None],\n",
    "             'min_samples_split':[2,5,10],\n",
    "             'min_samples_leaf':[1,5,10],\n",
    "             'bootstrap':[True,False],\n",
    "             'criterion':['entropy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator =clf1, param_grid=parameters,\n",
    "                          scoring='accuracy',\n",
    "                          cv=10,\n",
    "                          n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best paramters: {best_params})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1= RandomForestClassifier(**best_params)\n",
    "clf1.fit(x_train,y_train)\n",
    "print_score(clf1, xtrain_scaled, y_train, xtest_scaled, y_test, train=True)\n",
    "print_score(clf1, xtrain_scaled, y_train, xtest_scaled, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection for LR algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on Balanicing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
