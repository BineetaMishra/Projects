{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREDIT CARD FRAUD DETECTION\n",
    "\n",
    "<strong> Problem Statement </strong>\n",
    "In this project we want to identify fraudulent transactions with Credit Cards. Our objective is to build a Fraud detection system using Machine learning techniques. In the past, such systems were rule-based. Machine learning offers powerful new ways.\n",
    "\n",
    "The project uses a dataset of 300,000 fully anonymized transactions. Each transation is labelled either fraudulent or not fraudulent. Note that prevalence of fraudulent transactions is very low in the dataset. Less than 0.1% of the card transactions are fraudulent. This means that a system predicting each transaction to be normal can reach an accuracy of over 99.9% despite not detecting any fraudulent transaction. This will necessitate adjustment techniques.\n",
    "\n",
    "It is a CSV file, contains 31 features, the last feature is used to classify the transaction whether it is a fraud or not.\n",
    "\n",
    "<b>Case Study:</b> Fraud detection is important to e-coomerce store and lot of money is used to prevention.\n",
    "We have a e-commerce store that sells books. Thousands of books were sold last year and toda we will use transaction data to build Fraud Detection System. We will use publica;ly available dataset.\n",
    "\n",
    "<b> Business Problem:</b> Build a classifier that give a new transaction can say whether fraudulent or not with confidence.<br>\n",
    "<b> Outcome: </b>\n",
    "0:Non-Fradulent <br>\n",
    "1:Fradulent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> dropping some columns after EDA that these columns give no useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop(columns=['Time','V13','V15','V22','V23','V24','V25','V26','V27','V28'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V12       V14       V16       V17  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.617801 -0.311169 -0.470401  0.207971   \n",
       "1  0.085102 -0.255425 -0.166974  ...  1.065235 -0.143772  0.463917 -0.114805   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.066084 -0.165946 -2.890083  1.109969   \n",
       "3  0.377436 -1.387024 -0.054952  ...  0.178228 -0.287924 -1.059647 -0.684093   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.538196 -1.119670 -0.451449 -0.237033   \n",
       "\n",
       "        V18       V19       V20       V21  Amount  Class  \n",
       "0  0.025791  0.403993  0.251412 -0.018307  149.62      0  \n",
       "1 -0.183361 -0.145783 -0.069083 -0.225775    2.69      0  \n",
       "2 -0.121359 -2.261857  0.524980  0.247998  378.66      0  \n",
       "3  1.965775 -1.232622 -0.208038 -0.108300  123.50      0  \n",
       "4 -0.038195  0.803487  0.408542 -0.009431   69.99      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalising the amount range using Standard Scaler\n",
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Scaled_Amount']= sc.fit_transform(df['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['Amount'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>Class</th>\n",
       "      <th>Scaled_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V12       V14       V16       V17  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.617801 -0.311169 -0.470401  0.207971   \n",
       "1  0.085102 -0.255425 -0.166974  ...  1.065235 -0.143772  0.463917 -0.114805   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.066084 -0.165946 -2.890083  1.109969   \n",
       "3  0.377436 -1.387024 -0.054952  ...  0.178228 -0.287924 -1.059647 -0.684093   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.538196 -1.119670 -0.451449 -0.237033   \n",
       "\n",
       "        V18       V19       V20       V21  Class  Scaled_Amount  \n",
       "0  0.025791  0.403993  0.251412 -0.018307      0       0.244964  \n",
       "1 -0.183361 -0.145783 -0.069083 -0.225775      0      -0.342475  \n",
       "2 -0.121359 -2.261857  0.524980  0.247998      0       1.160686  \n",
       "3  1.965775 -1.232622 -0.208038 -0.108300      0       0.140534  \n",
       "4 -0.038195  0.803487  0.408542 -0.009431      0      -0.073403  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df.loc[:,df.columns != 'Class']\n",
    "y=df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>Scaled_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V14       V16  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.311169 -0.470401   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235 -0.143772  0.463917   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084 -0.165946 -2.890083   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228 -0.287924 -1.059647   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196 -1.119670 -0.451449   \n",
       "\n",
       "        V17       V18       V19       V20       V21  Scaled_Amount  \n",
       "0  0.207971  0.025791  0.403993  0.251412 -0.018307       0.244964  \n",
       "1 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775      -0.342475  \n",
       "2  1.109969 -0.121359 -2.261857  0.524980  0.247998       1.160686  \n",
       "3 -0.684093  1.965775 -1.232622 -0.208038 -0.108300       0.140534  \n",
       "4 -0.237033 -0.038195  0.803487  0.408542 -0.009431      -0.073403  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying machine learning algorithms\n",
    "<b> Creating a function that will give the Following output when any model is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def print_score(clf, x_train, y_train, x_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(x_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(x_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 99.92%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                       0           1  accuracy      macro avg   weighted avg\n",
      "precision       0.999332    0.885185  0.999197       0.942259       0.999136\n",
      "recall          0.999864    0.611253  0.999197       0.805558       0.999197\n",
      "f1-score        0.999598    0.723147  0.999197       0.861372       0.999123\n",
      "support    227454.000000  391.000000  0.999197  227845.000000  227845.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[227423     31]\n",
      " [   152    239]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 99.92%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0           1  accuracy     macro avg  weighted avg\n",
      "precision      0.999314    0.885714  0.999175      0.942514      0.999113\n",
      "recall         0.999859    0.613861  0.999175      0.806860      0.999175\n",
      "f1-score       0.999587    0.725146  0.999175      0.862367      0.999100\n",
      "support    56861.000000  101.000000  0.999175  56962.000000  56962.000000\n",
      "_______________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_LR = LogisticRegression(random_state=0)\n",
    "\n",
    "clf_LR.fit(x_train,y_train)\n",
    "print_score(clf_LR, x_train, y_train, x_test, y_test, train=True)\n",
    "print_score(clf_LR, x_train, y_train, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                  0      1  accuracy  macro avg  weighted avg\n",
      "precision       1.0    1.0       1.0        1.0           1.0\n",
      "recall          1.0    1.0       1.0        1.0           1.0\n",
      "f1-score        1.0    1.0       1.0        1.0           1.0\n",
      "support    227454.0  391.0       1.0   227845.0      227845.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[227454      0]\n",
      " [     0    391]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 99.93%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0           1  accuracy     macro avg  weighted avg\n",
      "precision      0.999560    0.826087   0.99928      0.912824      0.999253\n",
      "recall         0.999719    0.752475   0.99928      0.876097      0.999280\n",
      "f1-score       0.999640    0.787565   0.99928      0.893602      0.999263\n",
      "support    56861.000000  101.000000   0.99928  56962.000000  56962.000000\n",
      "_______________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_tree= DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "clf_tree.fit(x_train,y_train)\n",
    "print_score(clf_tree, x_train, y_train, x_test, y_test, train=True)\n",
    "print_score(clf_tree, x_train, y_train, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                  0      1  accuracy  macro avg  weighted avg\n",
      "precision       1.0    1.0       1.0        1.0           1.0\n",
      "recall          1.0    1.0       1.0        1.0           1.0\n",
      "f1-score        1.0    1.0       1.0        1.0           1.0\n",
      "support    227454.0  391.0       1.0   227845.0      227845.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[227454      0]\n",
      " [     0    391]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 99.95%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0           1  accuracy     macro avg  weighted avg\n",
      "precision      0.999631    0.930233  0.999526      0.964932      0.999508\n",
      "recall         0.999894    0.792079  0.999526      0.895987      0.999526\n",
      "f1-score       0.999763    0.855615  0.999526      0.927689      0.999507\n",
      "support    56861.000000  101.000000  0.999526  56962.000000  56962.000000\n",
      "_______________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf= RandomForestClassifier(random_state=0)\n",
    "\n",
    "clf_rf.fit(x_train,y_train)\n",
    "print_score(clf_rf, x_train, y_train, x_test, y_test, train=True)\n",
    "print_score(clf_rf, x_train, y_train, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "print(\"=======================Linear Kernel SVM==========================\")\n",
    "model_linear = SVC(kernel='linear')\n",
    "model_linear.fit(x_train, y_train)\n",
    "print_score(model_linear, x_train, y_train, x_test, y_test, train=True)\n",
    "print_score(model_linear, x_train, y_train, x_test, y_test, train=False)\n",
    "\n",
    "print(\"=======================Polynomial Kernel SVM==========================\")\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model_Poly = SVC(kernel='poly', degree=2, gamma='auto')\n",
    "model_Poly.fit(x_train, y_train)\n",
    "\n",
    "print_score(model_Poly, x_train, y_train, x_test, y_test, train=True)\n",
    "print_score(model_Poly, x_train, y_train, x_test, y_test, train=False)\n",
    "\n",
    "print(\"=======================Radial Kernel SVM==========================\")\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model_RBF = SVC(kernel='rbf', gamma=1)\n",
    "model_RBF.fit(x_train, y_train)\n",
    "\n",
    "print_score(model_RBF, x_train, y_train, x_test, y_test, train=True)\n",
    "print_score(model_RBF, x_train, y_train, x_test, y_test, train=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE # Recurssive Feature Elimination\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebineet\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass n_features_to_select=4 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Reducing the features to 20 from 42\n",
    "clf = LogisticRegression(random_state=0)\n",
    "rfe = RFE(clf, 4)\n",
    "rfe= rfe.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True False False False False False  True False False\n",
      "  True  True False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "# summarise the selection attributes\n",
    "# which columns are selected(True) and which are not (False)\n",
    "print(rfe.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V4', 'V10', 'V14', 'V16'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15,  8, 11,  1,  5, 10, 17,  2, 13,  1,  4, 16,  1,  1,  7, 14, 12,\n",
       "        6,  3,  9])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting Test Set\n",
    "clf.fit(x_train[x_train.columns[rfe.support_]],y_train)\n",
    "y_pred = clf.predict(x_test[x_test.columns[rfe.support_]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56853     8]\n",
      " [   42    59]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9991222218320986"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Making the confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm= confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V4</td>\n",
       "      <td>0.483711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V10</td>\n",
       "      <td>-0.286240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V14</td>\n",
       "      <td>-0.769235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V16</td>\n",
       "      <td>-0.293106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  features      coef\n",
       "0       V4  0.483711\n",
       "1      V10 -0.286240\n",
       "2      V14 -0.769235\n",
       "3      V16 -0.293106"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyzing Coefficients\n",
    "pd.concat([pd.DataFrame(x_train[x_train.columns[rfe.support_]].columns, columns = [\"features\"]),\n",
    "           pd.DataFrame(np.transpose(clf.coef_), columns = [\"coef\"])\n",
    "           ],axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Fold Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies= cross_val_score(estimator=clf_LR,\n",
    "                           X=x_train,\n",
    "                           y=y_train,\n",
    "                           cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99912221, 0.99918804, 0.99920999, 0.99929777, 0.99905638])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will show all 10 fold accuracies\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999174877658057"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies= cross_val_score(estimator=clf_tree,\n",
    "                           X=x_train,\n",
    "                           y=y_train,\n",
    "                           cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991178213259013"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies= cross_val_score(estimator=clf_rf,\n",
    "                           X=x_train,\n",
    "                           y=y_train,\n",
    "                           cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995479382913823"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "accuracies_rbf= cross_val_score(estimator=model_RBF,\n",
    "                           X=x_train,\n",
    "                           y=y_train,\n",
    "                           cv=5)\n",
    "\n",
    "accuracies_Poly= cross_val_score(estimator=model_Poly,\n",
    "                           X=x_train,\n",
    "                           y=y_train,\n",
    "                           cv=5)\n",
    "\n",
    "\n",
    "accuracies_linear= cross_val_score(estimator=model_linear,\n",
    "                           X=x_train,\n",
    "                           y=y_train,\n",
    "                           cv=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "accuracies_rbf.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "accuracies_Poly.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "accuracies_linear.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "The accuracy is so high because the dataset is an imbalanced datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with data imbalance part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>Scaled_Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22646</th>\n",
       "      <td>1.198567</td>\n",
       "      <td>0.231864</td>\n",
       "      <td>0.013675</td>\n",
       "      <td>0.559377</td>\n",
       "      <td>-0.187499</td>\n",
       "      <td>-1.225223</td>\n",
       "      <td>0.511650</td>\n",
       "      <td>-0.359399</td>\n",
       "      <td>-0.259776</td>\n",
       "      <td>-0.089030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519834</td>\n",
       "      <td>0.402407</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>-0.275740</td>\n",
       "      <td>-0.925099</td>\n",
       "      <td>0.093536</td>\n",
       "      <td>0.016065</td>\n",
       "      <td>-0.352293</td>\n",
       "      <td>-0.149727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155379</th>\n",
       "      <td>1.787031</td>\n",
       "      <td>-0.634216</td>\n",
       "      <td>-0.669182</td>\n",
       "      <td>0.375334</td>\n",
       "      <td>-0.201481</td>\n",
       "      <td>0.356438</td>\n",
       "      <td>-0.629464</td>\n",
       "      <td>0.054184</td>\n",
       "      <td>2.291408</td>\n",
       "      <td>-0.358451</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.637411</td>\n",
       "      <td>1.588988</td>\n",
       "      <td>0.644095</td>\n",
       "      <td>-0.407629</td>\n",
       "      <td>1.282694</td>\n",
       "      <td>-0.116457</td>\n",
       "      <td>0.025551</td>\n",
       "      <td>0.142614</td>\n",
       "      <td>0.120024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154833</th>\n",
       "      <td>1.922634</td>\n",
       "      <td>-0.503006</td>\n",
       "      <td>-0.281435</td>\n",
       "      <td>0.377774</td>\n",
       "      <td>-0.611322</td>\n",
       "      <td>-0.130655</td>\n",
       "      <td>-0.792329</td>\n",
       "      <td>0.098472</td>\n",
       "      <td>2.354033</td>\n",
       "      <td>-0.184685</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.273718</td>\n",
       "      <td>1.800721</td>\n",
       "      <td>0.724045</td>\n",
       "      <td>-0.019172</td>\n",
       "      <td>0.550563</td>\n",
       "      <td>0.074421</td>\n",
       "      <td>-0.254574</td>\n",
       "      <td>-0.332747</td>\n",
       "      <td>-0.213296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46134</th>\n",
       "      <td>-2.834727</td>\n",
       "      <td>1.680017</td>\n",
       "      <td>-0.434242</td>\n",
       "      <td>0.841575</td>\n",
       "      <td>-0.714881</td>\n",
       "      <td>-0.410424</td>\n",
       "      <td>-0.312219</td>\n",
       "      <td>0.884273</td>\n",
       "      <td>-0.722863</td>\n",
       "      <td>0.287040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881362</td>\n",
       "      <td>1.141090</td>\n",
       "      <td>0.301178</td>\n",
       "      <td>-0.136698</td>\n",
       "      <td>0.751629</td>\n",
       "      <td>0.897726</td>\n",
       "      <td>-0.724670</td>\n",
       "      <td>0.360846</td>\n",
       "      <td>-0.293258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145207</th>\n",
       "      <td>-0.097242</td>\n",
       "      <td>1.225410</td>\n",
       "      <td>-0.503553</td>\n",
       "      <td>-0.600707</td>\n",
       "      <td>0.962186</td>\n",
       "      <td>-0.849131</td>\n",
       "      <td>0.980430</td>\n",
       "      <td>-0.132985</td>\n",
       "      <td>0.056358</td>\n",
       "      <td>-0.538637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210882</td>\n",
       "      <td>-1.210196</td>\n",
       "      <td>0.289611</td>\n",
       "      <td>0.313790</td>\n",
       "      <td>-0.300381</td>\n",
       "      <td>-0.251957</td>\n",
       "      <td>0.177660</td>\n",
       "      <td>-0.369147</td>\n",
       "      <td>-0.341355</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109050</th>\n",
       "      <td>1.187481</td>\n",
       "      <td>0.209676</td>\n",
       "      <td>0.678692</td>\n",
       "      <td>1.484880</td>\n",
       "      <td>-0.440387</td>\n",
       "      <td>-0.445655</td>\n",
       "      <td>-0.003806</td>\n",
       "      <td>-0.126105</td>\n",
       "      <td>0.389967</td>\n",
       "      <td>-0.144330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926766</td>\n",
       "      <td>-0.310269</td>\n",
       "      <td>-0.447033</td>\n",
       "      <td>-0.045400</td>\n",
       "      <td>-0.498843</td>\n",
       "      <td>-0.044575</td>\n",
       "      <td>-0.099873</td>\n",
       "      <td>-0.048917</td>\n",
       "      <td>-0.313289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78045</th>\n",
       "      <td>1.236878</td>\n",
       "      <td>-0.463243</td>\n",
       "      <td>-0.175660</td>\n",
       "      <td>-0.799540</td>\n",
       "      <td>0.050956</td>\n",
       "      <td>0.459209</td>\n",
       "      <td>-0.330177</td>\n",
       "      <td>0.147344</td>\n",
       "      <td>-1.248713</td>\n",
       "      <td>0.483207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061054</td>\n",
       "      <td>0.181541</td>\n",
       "      <td>-0.651434</td>\n",
       "      <td>1.708905</td>\n",
       "      <td>-3.696550</td>\n",
       "      <td>-1.041269</td>\n",
       "      <td>-0.055726</td>\n",
       "      <td>0.336404</td>\n",
       "      <td>-0.293258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129013</th>\n",
       "      <td>0.922408</td>\n",
       "      <td>-0.242165</td>\n",
       "      <td>1.268954</td>\n",
       "      <td>2.615390</td>\n",
       "      <td>-0.850669</td>\n",
       "      <td>0.643381</td>\n",
       "      <td>-0.673174</td>\n",
       "      <td>0.417251</td>\n",
       "      <td>0.156498</td>\n",
       "      <td>0.676211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281575</td>\n",
       "      <td>0.170586</td>\n",
       "      <td>1.015714</td>\n",
       "      <td>-0.670630</td>\n",
       "      <td>0.658643</td>\n",
       "      <td>-0.446498</td>\n",
       "      <td>-0.074987</td>\n",
       "      <td>-0.021443</td>\n",
       "      <td>0.024150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268831</th>\n",
       "      <td>0.309445</td>\n",
       "      <td>-0.154803</td>\n",
       "      <td>0.506564</td>\n",
       "      <td>-1.958505</td>\n",
       "      <td>-0.200893</td>\n",
       "      <td>-0.203742</td>\n",
       "      <td>-0.016888</td>\n",
       "      <td>0.163345</td>\n",
       "      <td>-0.957102</td>\n",
       "      <td>0.243901</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.544105</td>\n",
       "      <td>0.023341</td>\n",
       "      <td>1.306089</td>\n",
       "      <td>-0.036605</td>\n",
       "      <td>-1.235516</td>\n",
       "      <td>0.835488</td>\n",
       "      <td>-0.027218</td>\n",
       "      <td>-0.159451</td>\n",
       "      <td>-0.273468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6867</th>\n",
       "      <td>-1.080766</td>\n",
       "      <td>0.013074</td>\n",
       "      <td>2.822803</td>\n",
       "      <td>-2.561226</td>\n",
       "      <td>-0.652153</td>\n",
       "      <td>-0.672249</td>\n",
       "      <td>0.210724</td>\n",
       "      <td>-0.096009</td>\n",
       "      <td>2.386985</td>\n",
       "      <td>-1.815125</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.239517</td>\n",
       "      <td>0.972398</td>\n",
       "      <td>0.361421</td>\n",
       "      <td>-0.361068</td>\n",
       "      <td>1.257180</td>\n",
       "      <td>-0.528683</td>\n",
       "      <td>0.326240</td>\n",
       "      <td>0.166826</td>\n",
       "      <td>-0.067006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "22646   1.198567  0.231864  0.013675  0.559377 -0.187499 -1.225223  0.511650   \n",
       "155379  1.787031 -0.634216 -0.669182  0.375334 -0.201481  0.356438 -0.629464   \n",
       "154833  1.922634 -0.503006 -0.281435  0.377774 -0.611322 -0.130655 -0.792329   \n",
       "46134  -2.834727  1.680017 -0.434242  0.841575 -0.714881 -0.410424 -0.312219   \n",
       "145207 -0.097242  1.225410 -0.503553 -0.600707  0.962186 -0.849131  0.980430   \n",
       "109050  1.187481  0.209676  0.678692  1.484880 -0.440387 -0.445655 -0.003806   \n",
       "78045   1.236878 -0.463243 -0.175660 -0.799540  0.050956  0.459209 -0.330177   \n",
       "129013  0.922408 -0.242165  1.268954  2.615390 -0.850669  0.643381 -0.673174   \n",
       "268831  0.309445 -0.154803  0.506564 -1.958505 -0.200893 -0.203742 -0.016888   \n",
       "6867   -1.080766  0.013074  2.822803 -2.561226 -0.652153 -0.672249  0.210724   \n",
       "\n",
       "              V8        V9       V10  ...       V12       V14       V16  \\\n",
       "22646  -0.359399 -0.259776 -0.089030  ...  0.519834  0.402407  0.013442   \n",
       "155379  0.054184  2.291408 -0.358451  ... -1.637411  1.588988  0.644095   \n",
       "154833  0.098472  2.354033 -0.184685  ... -2.273718  1.800721  0.724045   \n",
       "46134   0.884273 -0.722863  0.287040  ...  0.881362  1.141090  0.301178   \n",
       "145207 -0.132985  0.056358 -0.538637  ...  0.210882 -1.210196  0.289611   \n",
       "109050 -0.126105  0.389967 -0.144330  ...  0.926766 -0.310269 -0.447033   \n",
       "78045   0.147344 -1.248713  0.483207  ...  0.061054  0.181541 -0.651434   \n",
       "129013  0.417251  0.156498  0.676211  ... -0.281575  0.170586  1.015714   \n",
       "268831  0.163345 -0.957102  0.243901  ... -0.544105  0.023341  1.306089   \n",
       "6867   -0.096009  2.386985 -1.815125  ... -1.239517  0.972398  0.361421   \n",
       "\n",
       "             V17       V18       V19       V20       V21  Scaled_Amount  Class  \n",
       "22646  -0.275740 -0.925099  0.093536  0.016065 -0.352293      -0.149727      0  \n",
       "155379 -0.407629  1.282694 -0.116457  0.025551  0.142614       0.120024      0  \n",
       "154833 -0.019172  0.550563  0.074421 -0.254574 -0.332747      -0.213296      0  \n",
       "46134  -0.136698  0.751629  0.897726 -0.724670  0.360846      -0.293258      0  \n",
       "145207  0.313790 -0.300381 -0.251957  0.177660 -0.369147      -0.341355      0  \n",
       "109050 -0.045400 -0.498843 -0.044575 -0.099873 -0.048917      -0.313289      0  \n",
       "78045   1.708905 -3.696550 -1.041269 -0.055726  0.336404      -0.293258      0  \n",
       "129013 -0.670630  0.658643 -0.446498 -0.074987 -0.021443       0.024150      0  \n",
       "268831 -0.036605 -1.235516  0.835488 -0.027218 -0.159451      -0.273468      0  \n",
       "6867   -0.361068  1.257180 -0.528683  0.326240  0.166826      -0.067006      0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the training df by remerging X_train and y_train\n",
    "df_train = x_train.join(y_train)\n",
    "df_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227454\n",
      "-----------\n",
      "391\n",
      "-----------\n",
      "0    227454\n",
      "1       391\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df_train[df_train.Class==0]\n",
    "df_minority = df_train[df_train.Class==1]\n",
    "\n",
    "print(df_majority.Class.count())\n",
    "print(\"-----------\")\n",
    "print(df_minority.Class.count())\n",
    "print(\"-----------\")\n",
    "print(df_train.Class.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UpSampling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    227454\n",
       "0    227454\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=227454,    # to match majority class\n",
    "                                 random_state=587) # reproducible results\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "# Display new class counts\n",
    "df_upsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_upsampled = df_upsampled.drop(['Class'], axis= 1)\n",
    "y_upsampled = df_upsampled.Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression on UpSampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 80.52%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                       0              1  accuracy      macro avg  \\\n",
      "precision       0.719716       0.999777   0.80524       0.859746   \n",
      "recall          0.999864       0.610616   0.80524       0.805240   \n",
      "f1-score        0.836969       0.758175   0.80524       0.797572   \n",
      "support    227454.000000  227454.000000   0.80524  454908.000000   \n",
      "\n",
      "            weighted avg  \n",
      "precision       0.859746  \n",
      "recall          0.805240  \n",
      "f1-score        0.797572  \n",
      "support    454908.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[227423     31]\n",
      " [ 88567 138887]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 99.92%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0           1  accuracy     macro avg  weighted avg\n",
      "precision      0.999314    0.885714  0.999175      0.942514      0.999113\n",
      "recall         0.999859    0.613861  0.999175      0.806860      0.999175\n",
      "f1-score       0.999587    0.725146  0.999175      0.862367      0.999100\n",
      "support    56861.000000  101.000000  0.999175  56962.000000  56962.000000\n",
      "_______________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_LR = LogisticRegression(random_state=0)\n",
    "\n",
    "clf_LR.fit(x_train,y_train)\n",
    "print_score(clf_LR, x_upsampled, y_upsampled, x_test, y_test, train=True)\n",
    "print_score(clf_LR, x_upsampled, y_upsampled, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down-Sampling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    391\n",
       "0    391\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=391,     # to match minority class\n",
    "                                 random_state=24) # reproducible results\n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "# Display new class counts\n",
    "df_downsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_downsampled = df_downsampled.drop(['Class'], axis = 1)\n",
    "y_downsampled = df_downsampled.Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression on Down-Sampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 80.56%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.720074    1.000000  0.805627    0.860037      0.860037\n",
      "recall       1.000000    0.611253  0.805627    0.805627      0.805627\n",
      "f1-score     0.837259    0.758730  0.805627    0.797995      0.797995\n",
      "support    391.000000  391.000000  0.805627  782.000000    782.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[391   0]\n",
      " [152 239]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 99.92%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0           1  accuracy     macro avg  weighted avg\n",
      "precision      0.999314    0.885714  0.999175      0.942514      0.999113\n",
      "recall         0.999859    0.613861  0.999175      0.806860      0.999175\n",
      "f1-score       0.999587    0.725146  0.999175      0.862367      0.999100\n",
      "support    56861.000000  101.000000  0.999175  56962.000000  56962.000000\n",
      "_______________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_LR = LogisticRegression(random_state=0)\n",
    "\n",
    "clf_LR.fit(x_train,y_train)\n",
    "print_score(clf_LR, x_downsampled, y_downsampled, x_test, y_test, train=True)\n",
    "print_score(clf_LR, x_downsampled, y_downsampled, x_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Using cached imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.8.0-py3-none-any.whl (206 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\ebineet\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\ebineet\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\ebineet\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\ebineet\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ebineet\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.1.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.8.0 imblearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\ebineet\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable SMOTE object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-d4e7a25786cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m587\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx_SMOTE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_SMOTE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_SMOTE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_SMOTE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable SMOTE object"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=587)\n",
    "x_SMOTE, y_SMOTE = sm.fit(x_train, y_train)\n",
    "print(len(y_SMOTE))\n",
    "print(y_SMOTE.sum())\n",
    "print(y_SMOTE.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
